{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_partial_result(image):\n",
    "    plt.figure()\n",
    "    io.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def list_image(dir_path=\"images/\", manual_path=\"manual1/\",mask_path=\"mask/\"):\n",
    "    image_list = []\n",
    "    image_list.append(\"01_g\")\n",
    "    image_list.append(\"01_h\")\n",
    "    image_list.append(\"02_g\")\n",
    "    image_list.append(\"02_h\")\n",
    "    image_list.append(\"03_h\")\n",
    "    image_list.append(\"04_h\")\n",
    "    image_list.append(\"04_g\")\n",
    "    image_paths =  [[os.path.join(dir_path, file+\".jpg\"), os.path.join(manual_path, file+\".tif\"),os.path.join(mask_path, file+\"_mask.tif\")] for file in image_list]\n",
    "    return [[cv2.imread(image_path[0], cv2.IMREAD_COLOR), cv2.imread(image_path[1], cv2.IMREAD_COLOR),cv2.imread(image_path[2], cv2.IMREAD_COLOR)]for image_path in image_paths]\n",
    "\n",
    "def morphology(image, radius):\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_OPEN,\n",
    "                          cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (radius, radius)), iterations=1)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (radius, radius)),\n",
    " iterations=1)\n",
    "\n",
    "def prepare_image(image):\n",
    "    b, image, r = cv2.split(image)\n",
    "#     print_partial_result(image)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    prepared_image = clahe.apply(image)\n",
    "    background = morphology(prepared_image, 5)\n",
    "    background = morphology(background, 15)\n",
    "    background = morphology(background, 25)\n",
    "    prepared_image = cv2.subtract(background, prepared_image)\n",
    "    prepared_image = clahe.apply(prepared_image)\n",
    "#     print_partial_result(prepared_image)\n",
    "\n",
    "    _, transformed_image = cv2.threshold(prepared_image, 15, 255, cv2.THRESH_BINARY)\n",
    "    mask = np.ones(prepared_image.shape[:2], dtype=\"uint8\") * 255\n",
    "    contours, _ = cv2.findContours(transformed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) <= 200:\n",
    "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "    prepared_image = cv2.bitwise_and(prepared_image, mask)\n",
    "    _, prepared_image = cv2.threshold(prepared_image, 15, 255, cv2.THRESH_BINARY)\n",
    "    return prepared_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_statistic(prepared_image, manual, mask):\n",
    "    in_scope = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "\n",
    "    for i in range(len(prepared_image)):\n",
    "        for j in range(len(prepared_image[0])):\n",
    "            if mask[i,j,1] == 255:\n",
    "                in_scope +=1\n",
    "                if  manual[i,j,1] == 255:\n",
    "                    if prepared_image[i,j] == 255:\n",
    "                        TP +=1\n",
    "                    else:\n",
    "                        FN +=1\n",
    "                else:\n",
    "                    if prepared_image[i,j] == 0:\n",
    "                        TN +=1\n",
    "                    else:\n",
    "                        FP +=1\n",
    "\n",
    "    accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "    sensitivity = TP/(TP + FN)\n",
    "    specificity = TN/(TN + FP)\n",
    "    mean_geometric = gmean([specificity,sensitivity])\n",
    "    print(\"confusion matrix:\")\n",
    "    print(TP,\",\", FP)\n",
    "    print(FN,\",\",TN)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    print(\"sensitivity:\", sensitivity)\n",
    "    print(\"specificity:\", specificity)\n",
    "    print(\"geometric mean of sensitivity and specificity\", mean_geometric)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_for_knn(image):\n",
    "    processed = []\n",
    "    for i in range(len(image)):\n",
    "        left =2\n",
    "        right = 2\n",
    "        if i<=2:\n",
    "            left = i\n",
    "        if i >= len(image)-2:\n",
    "            right = len(image)-i \n",
    "        for j in  range(len(image[0])):\n",
    "            up = 2 \n",
    "            down = 2\n",
    "            if j<=2:\n",
    "                up = j\n",
    "            if j>= len(image[0])-2:\n",
    "                down = len(image[0])-j\n",
    "\n",
    "            fragment = image[i-left:i+right,j-up:j+down,:]\n",
    "            _, g, _ = cv2.split(fragment)\n",
    "            # moments = cv2.moments(g)\n",
    "            Humoments = cv2.HuMoments( cv2.moments(g)).flatten()\n",
    "\n",
    "            # try:\n",
    "            processed.append(Humoments)\n",
    "            del fragment\n",
    "            del g\n",
    "            # except:\n",
    "                # print(\"error on indices:\", i,j)\n",
    "                # break\n",
    "    return processed\n",
    "\n",
    "def process_knn(image,knn,manual,mask):\n",
    "    print(\"Processing knn...\")\n",
    "    rows,cols,_ = manual.shape\n",
    "    X_test = process_image_for_knn(image)\n",
    "    y_pred = []\n",
    "    y_pred = knn.predict(X_test)\n",
    "    prepared_image = y_pred.reshape((rows, cols))\n",
    "    show_statistic(prepared_image, manual, mask)\n",
    "    b, g, r = cv2.split(image)\n",
    "    new_image=image.copy()\n",
    "    new_image[:,:,2] = cv2.add(b,prepared_image)\n",
    "    new_image[:,:,0] = cv2.add(r,prepared_image)\n",
    "    new_image[:,:,1] = cv2.add(g,prepared_image)\n",
    "\n",
    "    return prepared_image,new_image\n",
    "\n",
    "def prepare_test(image,manual,knn):\n",
    "    X_train= process_image_for_knn(image)\n",
    "    b, manual, r = cv2.split(manual)\n",
    "    y_train = manual.flatten()\n",
    "    knn.fit(X_train, y_train)\n",
    "    pass\n",
    "\n",
    "def test_knn(image, manual):\n",
    "    X_test = process_image_for_knn(image)\n",
    "    b, manual, r = cv2.split(manual)\n",
    "    y_test = manual.flatten()\n",
    "    print(\"Hold out accuracy: \",knn.score(X_test, y_test))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    for i,[image,manual,mask] in enumerate(list_image()): \n",
    "        #my imshow inverts r and b channel, for visualisation purposes I swap them too\n",
    "        plt.figure(0)\n",
    "        b, g, r = cv2.split(image)\n",
    "        new_image=image.copy()\n",
    "        new_image[:,:,2] = b\n",
    "        new_image[:,:,0] = r\n",
    "        io.imshow(new_image)\n",
    "        plt.figure(1)\n",
    "        prepared_image = prepare_image(image)\n",
    "        io.imshow(prepared_image)\n",
    "        plt.figure(2)\n",
    "        io.imshow(manual)\n",
    "        plt.figure(3)\n",
    "        new_image=image.copy()\n",
    "        new_image[:,:,2] = cv2.add(b,prepared_image)\n",
    "        new_image[:,:,1] = cv2.add(g,prepared_image)\n",
    "        new_image[:,:,0] = cv2.add(r,prepared_image)\n",
    "        io.imshow(new_image)\n",
    "        plt.show()\n",
    "        show_statistic(prepared_image, manual, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "X_train=[]\n",
    "y_train =[] \n",
    "for i,[image,manual,mask] in enumerate(list_image()): \n",
    "    if i == 0:\n",
    "        print(\"Preparing train model for knn...\")\n",
    "        x,y,z = image.shape\n",
    "        plt.figure(0)\n",
    "        io.imshow(image)\n",
    "        plt.figure(1)\n",
    "        io.imshow(manual)\n",
    "        prepare_test(image,manual,knn)\n",
    "        print(\"Preparing done!\")\n",
    "    elif i == 6:\n",
    "        test_knn(image[0:x,0:y//2,:], manual[0:x//2,0:y//2,:])\n",
    "    else :\n",
    "        print(\"knn processing...\")\n",
    "#         plt.figure(0)\n",
    "#         x,y,z = image.shape\n",
    "#         io.imshow(image)     \n",
    "#         io.imshow(manual[0:x//4,0:y//4,:])\n",
    "        prepared_image, new_image = process_knn(image,knn,manual,mask)\n",
    "        print(\"result\")\n",
    "        plt.figure(1)\n",
    "        io.imshow(prepared_image, cmap='gray')\n",
    "        plt.figure(2)\n",
    "        io.imshow(new_image)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}